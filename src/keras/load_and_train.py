import keras
import numpy as np
from keras.models import load_model
from keras.preprocessing.image import ImageDataGenerator
from com.chandler.irac.datasets.Cifa10Loader import Cifa10Loader

batch_size = 128
num_classes = 10
epochs = 50



'''
10000x5 data 3072 pixels 10 outcomes
'''
loader = Cifa10Loader()
x_train, y_train, x_test, y_test = loader.load_cifar10('../../../../../data/CIFAR10/', 5)
print('x_train shape:', x_train.shape)
print('y_train shape:', y_train.shape)

#reshape data
x_train = x_train.reshape(x_train.shape[0], 3, 32, 32)
x_test = x_test.reshape(x_test.shape[0], 3, 32, 32)

#swap axis
x_train = np.swapaxes(x_train, 1, 2)
x_train = np.swapaxes(x_train, 2, 3)
x_test = np.swapaxes(x_test, 1, 2)
x_test = np.swapaxes(x_test, 2, 3)
        
print('x_train shape:', x_train.shape)
print('y_train shape:', y_train.shape)


# Convert class vectors to binary class matrices.
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)
#data pre-processing
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255




#load model
model = load_model('saved/cifar10_best.h5')
#plot model graph
from keras.utils import plot_model
plot_model(model, to_file='load_model.png', show_shapes=True)


# This will do preprocessing and realtime data augmentation:
datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=True,  # randomly flip images
        vertical_flip=False)  # randomly flip images

# Compute quantities required for feature-wise normalization
# (std, mean, and principal components if ZCA whitening is applied).
datagen.fit(x_train)

#Tensorboard
tensor_board = keras.callbacks.TensorBoard(log_dir='logs', histogram_freq=0, batch_size=batch_size,
                             write_graph=True, write_grads=False, write_images=False, 
                             embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)

check_point = keras.callbacks.ModelCheckpoint("saved/cifar10_best.h5", monitor='val_loss', 
                                              verbose=0, save_best_only=True, save_weights_only=False, 
                                              mode='auto', period=1)

early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=0, mode='auto')

# Fit the model on the batches generated by datagen.flow().
history = model.fit_generator(datagen.flow(x_train, y_train,
                                     batch_size=batch_size),
                        steps_per_epoch=x_train.shape[0] // batch_size,
                        epochs=epochs,
                        validation_data=(x_test, y_test),
                        callbacks = [tensor_board,check_point,early_stopping],
                        verbose=2)



# list all data in history
print(history.history.keys())
# summarize history for accuracy
import matplotlib.pyplot as plt

plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

                        
#model.save_weights('cifar10_weights_reg.h5')
#model.save('saved/cifar10_reg2.h5')
